{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 76727,
          "databundleVersionId": 9045607,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "0.99+ Acc, Binary Classifier",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'playground-series-s4e8:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F76727%2F9045607%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240828%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240828T105824Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1854267c167371753d2537b0640a405362928b413dd93493e2a9f6fb9a242b0ec5a845977f19064d7d66cd482422db29e6ce0cbd9b81bb25a3b2dd0bfb00c44fc82aacc118fd004b01ff7bbbc6f516a40ff3d8ca18ba49c27f8bd4646652bb9b469cc20868971a0aae6f743c574cf8f63172bc33afdc73ed668e7121fdc2b2c24661f5a487daada36081065a40d692e9dbccfe3ceab7b76a565d86058d7e5446bd80912341eae1745e843c9745f4a9a5ceb529699092c3a14d0b2e6684802290448a66996aa711a73930dca890819991999be8d536e4893b9d9ab886810cf37ae174afe9f47c907c69ae60f76ef61f069c4e257912d2dffb9991de1d707d08e5'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "r2jhJpPBowlD"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-08-25T14:33:35.377987Z",
          "iopub.execute_input": "2024-08-25T14:33:35.379273Z",
          "iopub.status.idle": "2024-08-25T14:33:36.767431Z",
          "shell.execute_reply.started": "2024-08-25T14:33:35.379207Z",
          "shell.execute_reply": "2024-08-25T14:33:36.765962Z"
        },
        "trusted": true,
        "id": "OMPIrPG_owlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "df = pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv')\n",
        "df_test = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:33:36.768982Z",
          "iopub.execute_input": "2024-08-25T14:33:36.769637Z",
          "iopub.status.idle": "2024-08-25T14:33:54.598538Z",
          "shell.execute_reply.started": "2024-08-25T14:33:36.769587Z",
          "shell.execute_reply": "2024-08-25T14:33:54.596923Z"
        },
        "trusted": true,
        "id": "8uoN4hihowlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:33:54.600522Z",
          "iopub.execute_input": "2024-08-25T14:33:54.600941Z",
          "iopub.status.idle": "2024-08-25T14:33:54.636375Z",
          "shell.execute_reply.started": "2024-08-25T14:33:54.600897Z",
          "shell.execute_reply": "2024-08-25T14:33:54.634963Z"
        },
        "trusted": true,
        "id": "CpT54lN7owlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_rows = df.isnull().sum()\n",
        "print(missing_rows)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:33:54.640503Z",
          "iopub.execute_input": "2024-08-25T14:33:54.640925Z",
          "iopub.status.idle": "2024-08-25T14:33:59.651175Z",
          "shell.execute_reply.started": "2024-08-25T14:33:54.640886Z",
          "shell.execute_reply": "2024-08-25T14:33:59.649782Z"
        },
        "trusted": true,
        "id": "Wf4yEsC4owlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_rows_test = df_test.isnull().sum()\n",
        "print(missing_rows_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:33:59.65284Z",
          "iopub.execute_input": "2024-08-25T14:33:59.653268Z",
          "iopub.status.idle": "2024-08-25T14:34:02.803694Z",
          "shell.execute_reply.started": "2024-08-25T14:33:59.653227Z",
          "shell.execute_reply": "2024-08-25T14:34:02.802467Z"
        },
        "trusted": true,
        "id": "z_wdu1J2owlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df[['class', 'id']]\n",
        "df = df.drop('class', axis=1)\n",
        "df = df.drop('id', axis=1)\n",
        "y_test = df_test[['id']]\n",
        "df_test = df_test.drop('id', axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:34:02.805448Z",
          "iopub.execute_input": "2024-08-25T14:34:02.805982Z",
          "iopub.status.idle": "2024-08-25T14:34:04.895061Z",
          "shell.execute_reply.started": "2024-08-25T14:34:02.805924Z",
          "shell.execute_reply": "2024-08-25T14:34:04.893298Z"
        },
        "trusted": true,
        "id": "AyungA9IowlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def advanced_impute(df, columns=None, chunk_size=10000):\n",
        "    if columns is None:\n",
        "        columns = df.columns.tolist()\n",
        "\n",
        "    for col in columns:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Column '{col}' not found in the dataframe\")\n",
        "\n",
        "    numeric_columns = df[columns].select_dtypes(include=[np.number]).columns\n",
        "    categorical_columns = df[columns].select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "    # Process numeric columns\n",
        "    if len(numeric_columns) > 0:\n",
        "        for col in numeric_columns:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                # Use median for imputation (more robust than mean)\n",
        "                median = df[col].median()\n",
        "                df[col].fillna(median, inplace=True)\n",
        "\n",
        "    # Process categorical columns\n",
        "    if len(categorical_columns) > 0:\n",
        "        for col in categorical_columns:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                if df[col].isnull().sum() / len(df) < 0.1:\n",
        "                    mode = df[col].mode()[0]\n",
        "                    df[col].fillna(mode, inplace=True)\n",
        "                else:\n",
        "                    df[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "    # Check for any remaining missing values\n",
        "    remaining_missing = df[columns].isnull().sum()\n",
        "    if remaining_missing.sum() > 0:\n",
        "        print(\"Remaining missing values:\")\n",
        "        print(remaining_missing[remaining_missing > 0])\n",
        "\n",
        "        # Use simple imputation for any remaining missing values\n",
        "        if len(numeric_columns) > 0:\n",
        "            numeric_imputer = SimpleImputer(strategy='median')\n",
        "            for start in range(0, len(df), chunk_size):\n",
        "                end = start + chunk_size\n",
        "                df.iloc[start:end, df.columns.get_indexer(numeric_columns)] = numeric_imputer.fit_transform(df.iloc[start:end][numeric_columns])\n",
        "\n",
        "        if len(categorical_columns) > 0:\n",
        "            cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "            for start in range(0, len(df), chunk_size):\n",
        "                end = start + chunk_size\n",
        "                df.iloc[start:end, df.columns.get_indexer(categorical_columns)] = cat_imputer.fit_transform(df.iloc[start:end][categorical_columns])\n",
        "\n",
        "    return df[columns]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:34:04.897035Z",
          "iopub.execute_input": "2024-08-25T14:34:04.897622Z",
          "iopub.status.idle": "2024-08-25T14:34:04.916931Z",
          "shell.execute_reply.started": "2024-08-25T14:34:04.897561Z",
          "shell.execute_reply": "2024-08-25T14:34:04.915065Z"
        },
        "trusted": true,
        "id": "X92Qts32owlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform imputation for df\n",
        "df_final = advanced_impute(df)\n",
        "\n",
        "# Check for any remaining missing values in df_final\n",
        "print(\"\\nFinal check for missing values in df_final:\")\n",
        "print(df_final.isnull().sum())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:34:04.91863Z",
          "iopub.execute_input": "2024-08-25T14:34:04.919285Z",
          "iopub.status.idle": "2024-08-25T14:34:37.630755Z",
          "shell.execute_reply.started": "2024-08-25T14:34:04.919233Z",
          "shell.execute_reply": "2024-08-25T14:34:37.629252Z"
        },
        "trusted": true,
        "id": "_mynSi5VowlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform imputation for df_test\n",
        "df_test_final = advanced_impute(df_test)\n",
        "\n",
        "# Check for any remaining missing values in df_test_final\n",
        "print(\"\\nFinal check for missing values in df_test_final:\")\n",
        "print(df_test_final.isnull().sum())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:34:37.632228Z",
          "iopub.execute_input": "2024-08-25T14:34:37.632712Z",
          "iopub.status.idle": "2024-08-25T14:34:59.64152Z",
          "shell.execute_reply.started": "2024-08-25T14:34:37.632669Z",
          "shell.execute_reply": "2024-08-25T14:34:59.640109Z"
        },
        "trusted": true,
        "id": "uFNu_kkDowlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numeric and categorical columns\n",
        "numeric_columns = df_final.select_dtypes(include=[np.number]).columns\n",
        "categorical_columns = df_final.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Standardize numerical columns\n",
        "scaler = StandardScaler()\n",
        "df_final[numeric_columns] = scaler.fit_transform(df_final[numeric_columns])\n",
        "df_test_final[numeric_columns] = scaler.transform(df_test_final[numeric_columns])\n",
        "\n",
        "# Ordinal encode categorical columns\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "df_final[categorical_columns] = encoder.fit_transform(df_final[categorical_columns])\n",
        "df_test_final[categorical_columns] = encoder.transform(df_test_final[categorical_columns])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:34:59.643187Z",
          "iopub.execute_input": "2024-08-25T14:34:59.643588Z",
          "iopub.status.idle": "2024-08-25T14:35:42.718357Z",
          "shell.execute_reply.started": "2024-08-25T14:34:59.643547Z",
          "shell.execute_reply": "2024-08-25T14:35:42.716717Z"
        },
        "trusted": true,
        "id": "jQwEGvXJowlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlations\n",
        "correlations = df_final.corr().abs()\n",
        "\n",
        "# Get the top 3 strongest correlations\n",
        "top_correlations = correlations.unstack().sort_values(ascending=False).drop_duplicates()\n",
        "top_3_correlations = top_correlations[1:4]  # Exclude the diagonal (correlation of 1 with itself)\n",
        "\n",
        "print(\"Top 3 strongest correlations:\")\n",
        "print(top_3_correlations)\n",
        "\n",
        "# Create 3 new features based on the top correlations\n",
        "for i, (pair, corr_value) in enumerate(top_3_correlations.items(), 1):\n",
        "    feature1, feature2 = pair\n",
        "    new_feature_name = f'new_feature_{i}'\n",
        "    df_final[new_feature_name] = df_final[feature1] * df_final[feature2]\n",
        "    df_test_final[new_feature_name] = df_test_final[feature1] * df_test_final[feature2]\n",
        "    print(f\"Created {new_feature_name} from {feature1} and {feature2}\")\n",
        "\n",
        "print(\"\\nShape of final training set:\", df_final.shape)\n",
        "print(\"Shape of final test set:\", df_test_final.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:37:44.356545Z",
          "iopub.execute_input": "2024-08-25T14:37:44.357136Z",
          "iopub.status.idle": "2024-08-25T14:37:48.449407Z",
          "shell.execute_reply.started": "2024-08-25T14:37:44.357087Z",
          "shell.execute_reply": "2024-08-25T14:37:48.44805Z"
        },
        "trusted": true,
        "id": "TiKRqjM7owlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = [\n",
        "    'stem-width',\n",
        "    'gill-attachment',\n",
        "    'cap-surface',\n",
        "    'gill-spacing',\n",
        "    'stem-color',\n",
        "    'stem-height',\n",
        "    'gill-color',\n",
        "    'cap-diameter',\n",
        "    'new_feature_1',\n",
        "    'stem-surface',\n",
        "    'cap-color',\n",
        "    'cap-shape',\n",
        "    'stem-root',\n",
        "    'new_feature_3',\n",
        "    'does-bruise-or-bleed',\n",
        "    'ring-type',\n",
        "    'habitat',\n",
        "    'has-ring',\n",
        "    'new_feature_2',\n",
        "    'spore-print-color'\n",
        "]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:39:44.149444Z",
          "iopub.execute_input": "2024-08-25T14:39:44.150093Z",
          "iopub.status.idle": "2024-08-25T14:39:44.158738Z",
          "shell.execute_reply.started": "2024-08-25T14:39:44.150041Z",
          "shell.execute_reply": "2024-08-25T14:39:44.157053Z"
        },
        "trusted": true,
        "id": "BpQj6NCcowlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the final DataFrames\n",
        "df_final = df_final[feature_names]\n",
        "df_test_final = df_test_final[feature_names]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:40:10.066349Z",
          "iopub.execute_input": "2024-08-25T14:40:10.066953Z",
          "iopub.status.idle": "2024-08-25T14:40:10.655504Z",
          "shell.execute_reply.started": "2024-08-25T14:40:10.066906Z",
          "shell.execute_reply": "2024-08-25T14:40:10.654203Z"
        },
        "trusted": true,
        "id": "vL0_TIjvowlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training data 90/10 for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(df_final, y_train['class'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Encode the target variable\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_val_encoded = le.transform(y_val)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Train XGBoost Classifier\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "xgb_classifier.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Train CatBoost Classifier\n",
        "cat_classifier = CatBoostClassifier(random_state=42, verbose=0)\n",
        "cat_classifier.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Make predictions on validation set\n",
        "y_pred_rf_val = rf_classifier.predict(X_val)\n",
        "y_pred_xgb_val = xgb_classifier.predict(X_val)\n",
        "y_pred_cat_val = cat_classifier.predict(X_val)\n",
        "\n",
        "# Calculate individual model accuracies on validation set\n",
        "acc_rf = accuracy_score(y_val_encoded, y_pred_rf_val)\n",
        "acc_xgb = accuracy_score(y_val_encoded, y_pred_xgb_val)\n",
        "acc_cat = accuracy_score(y_val_encoded, y_pred_cat_val)\n",
        "\n",
        "print(f\"Random Forest Classifier Accuracy: {acc_rf:.4f}\")\n",
        "print(f\"XGBoost Classifier Accuracy: {acc_xgb:.4f}\")\n",
        "print(f\"CatBoost Classifier Accuracy: {acc_cat:.4f}\")\n",
        "\n",
        "# Combine the predictions for validation set\n",
        "y_pred_ensemble_val = (y_pred_rf_val + y_pred_xgb_val + y_pred_cat_val) / 3\n",
        "y_pred_ensemble_val = (y_pred_ensemble_val > 0.5).astype(int)  # Convert probabilities to class labels\n",
        "\n",
        "# Calculate the ensemble accuracy on validation set\n",
        "acc_ensemble = accuracy_score(y_val_encoded, y_pred_ensemble_val)\n",
        "print(f\"\\nEnsemble Accuracy on Validation Set: {acc_ensemble:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T14:50:46.376754Z",
          "iopub.execute_input": "2024-08-25T14:50:46.378172Z",
          "iopub.status.idle": "2024-08-25T15:27:28.83914Z",
          "shell.execute_reply.started": "2024-08-25T14:50:46.378115Z",
          "shell.execute_reply": "2024-08-25T15:27:28.837721Z"
        },
        "trusted": true,
        "id": "5qdx_ansowlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_rf_test = rf_classifier.predict(df_test_final)\n",
        "y_pred_xgb_test = xgb_classifier.predict(df_test_final)\n",
        "y_pred_cat_test = cat_classifier.predict(df_test_final)\n",
        "\n",
        "# Combine the predictions for test set\n",
        "y_pred_ensemble_test = (y_pred_rf_test + y_pred_xgb_test + y_pred_cat_test) / 3\n",
        "y_pred_ensemble_test = (y_pred_ensemble_test > 0.5).astype(int)  # Convert probabilities to class labels\n",
        "\n",
        "# Convert numeric predictions back to 'p' and 'e'\n",
        "y_pred_final = le.inverse_transform(y_pred_ensemble_test)\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': y_test['id'],\n",
        "    'class': y_pred_final\n",
        "})\n",
        "\n",
        "# Save submission to CSV\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"\\nSubmission file 'submission.csv' has been created.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-25T15:27:56.553997Z",
          "iopub.execute_input": "2024-08-25T15:27:56.55473Z",
          "iopub.status.idle": "2024-08-25T15:29:40.851153Z",
          "shell.execute_reply.started": "2024-08-25T15:27:56.554656Z",
          "shell.execute_reply": "2024-08-25T15:29:40.848484Z"
        },
        "trusted": true,
        "id": "dZVcw1--owlK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}